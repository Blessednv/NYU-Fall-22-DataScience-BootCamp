{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWUVAxiiRu9f"
      },
      "source": [
        "### Training a Machine Learning model for regression problem "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhHqjNe1Ru9k"
      },
      "outputs": [],
      "source": [
        "# If you'd like to install packages that aren't installed by default, uncomment the last two lines of this cell and replace <package list> with a list of your packages.\n",
        "# This will ensure your notebook has all the dependencies and works everywhere\n",
        "\n",
        "#import sys\n",
        "#!{sys.executable} -m pip install <package list>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUVhkHQgRu9r"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import missingno as mno\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.preprocessing import LabelBinarizer, Normalizer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", 101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vioOxdNRu9v"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztLn1zf6Ru9w"
      },
      "source": [
        "Column | Description\n",
        ":---|:---\n",
        "`id` | Record index\n",
        "`timestamp` | Datetime (YYYY:MM:DD HH:MM:SS) when data was collected\n",
        "`country` | Current country of employment\n",
        "`employment_status` | Whether a candidate is Full time, Part time, Independent or freelancer or company owner\n",
        "`job_title` | Current job title of the candidate\n",
        "`job_years` | Total job experience (in Years)\n",
        "`is_manager` | Whether the candidate holds a managerial position or not (Yes or No)\n",
        "`hours_per_week` | No. of hours per day committed to the current job\n",
        "`telecommute_days_per_week` | No. of telecommuting days per week (working from home)\n",
        "`education` | The highest degree in education the candidate has received\n",
        "`is_education_computer_related` | Is the education related to the field of computer science (Yes or No)\n",
        "`certifications` | Does the candidate have any relevant certifications (Yes or No)\n",
        "`salary` | Monthly Salary (in US $$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOL82B_Ru9x"
      },
      "source": [
        "## Data Wrangling & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uknzSkP0Ru9y"
      },
      "outputs": [],
      "source": [
        "# Dataset is already loaded below\n",
        "data = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RPGEGxjRu91"
      },
      "outputs": [],
      "source": [
        "# Dimensions of training data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTJJ5_68Ru97"
      },
      "outputs": [],
      "source": [
        "# Print first few rows of data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-wzY-21Ru9_"
      },
      "outputs": [],
      "source": [
        "# Explore columns\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKVtaBgbRu-D",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Description\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wATW7SYBRu-G"
      },
      "outputs": [],
      "source": [
        "# Info\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFtZHgR9Ru-K",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Check Datatypes\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTFRZapvRu-R",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Print total missing values in each column\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Check the distribution for the null values\n",
        "mno.matrix(data, figsize = (20, 6))"
      ],
      "metadata": {
        "id": "Hv8VctNfTZp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MtVUnRGRu-Y"
      },
      "outputs": [],
      "source": [
        "# replace NANs in hours_per_week with median value of the column  \n",
        "data.loc[data['hours_per_week'].isna(), 'hours_per_week'] = data['hours_per_week'].median()\n",
        "data.loc[data['telecommute_days_per_week'].isna(), 'telecommute_days_per_week'] = data['telecommute_days_per_week'].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1tkT_hbRu-b"
      },
      "source": [
        "##### Next We have the some missing values in is_education_computer_related column which is a categorical variable. So we can't just impute these missing values. Best way to deal with it is to remove all rows for which this column has a nan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeTETmz1Ru-d"
      },
      "outputs": [],
      "source": [
        "# drop missing vals\n",
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOodMqPyRu-g",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# now check total missing vals in every column\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpT6bvWDRu-k",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Confirm that all missing values are gone.\n",
        "mno.matrix(data, figsize = (20, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RniPI_YJRu-n"
      },
      "source": [
        "## Visualization, Modeling, Machine Learning\n",
        "\n",
        "Build a model that can predict salary and identify how different features influence their decision? Please explain your findings effectively to technical and non-technical audiences using comments and visualizations, if appropriate.\n",
        "- **Build an optimized model that effectively solves the business problem.**\n",
        "- **The model would be evaluated on the basis of mean absolute error.**\n",
        "- **Read the test.csv file and prepare features for testing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZKhZ_klRu-o",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Loading Test data\n",
        "test = pd.read_csv('test.csv')\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnSSLHUORu-q",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Print first couple of rows of test data\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxndvA1gRu-t"
      },
      "outputs": [],
      "source": [
        "# check if there are any missing vals in test data or not\n",
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN9M_T51Ru-w"
      },
      "outputs": [],
      "source": [
        "# impute missing vals in hours_per_week column in test data with median value \n",
        "test.loc[test['hours_per_week'].isna(), 'hours_per_week'] = test['hours_per_week'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKd6cwEgRu-z",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Confirm that all missing values are gone in test data.\n",
        "mno.matrix(test, figsize = (20, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2lQAGgVRu-2"
      },
      "outputs": [],
      "source": [
        "# let's encode the categorical features in data only for analysis\n",
        "\n",
        "train_data = data.copy()\n",
        "\n",
        "cols = ['employment_status', 'job_title', 'is_manager', 'certifications', \n",
        "        'education', 'is_education_computer_related']\n",
        "\n",
        "for c in cols: # traverse each column\n",
        "    for i, item in enumerate(train_data[c].unique().tolist()): \n",
        "      ## for a column create traverse all unique values in it using 'item'\n",
        "        train_data.loc[train_data[c] == item, c] = i\n",
        "\n",
        "    print(\"Actual values in column:\", c, \"\\n\",  data[c].unique().tolist(), '\\n')\n",
        "    print(\"Encoded values in column:\", c, \"\\n\", train_data[c].unique().tolist(), '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns"
      ],
      "metadata": {
        "id": "6vdSy8ENeU1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuFqEPktRu-5"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7WcaeLuRu-6",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# joint plots for numeric variables\n",
        "\n",
        "cols = [\"job_years\", \"hours_per_week\"]\n",
        "for c in cols:\n",
        "    sns.jointplot(x=c, y=\"salary\", data=data, kind = 'reg', height = 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqc0bKuGRu-9"
      },
      "source": [
        "##### From the plots above we can clearly see that job_years has a relation with salary. The more job_years means more monthly earning(salary). Similar trend is visible for hours_per_week variable in relation to the target variable (salary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_doKJzrRu--",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# dist plots for numeric variables\n",
        "cols = [\"job_years\", \"hours_per_week\"]\n",
        "for c in cols:\n",
        "    sns.distplot(data[c])\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsHOe3d1Ru_C"
      },
      "source": [
        "##### The distributions plotted above are interesting. For job_years, we see a slightly skewed distribution which shows that majority of professionals in our data have less than 10 years of total job experience. For hours_per_week we see a somewhat bimdal distribution showing that most people work from 40 to 45 hours per week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrL-_iFmRu_C",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# distribution of target variable\n",
        "sns.distplot(data['salary'])\n",
        "plt.grid()\n",
        "plt.title('Distribution of Target Variable in Data')\n",
        "plt.show()\n",
        "print('max:', np.max(data['salary']))\n",
        "print('min:', np.min(data['salary']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tptL12j7Ru_F"
      },
      "source": [
        "##### For target variable i.e. salary we can see a smooth normal distribution with a bulge at the mean salary point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_qRi9KuRu_G",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# bar plots for categorical features\n",
        "cols = ['employment_status', 'job_title', 'is_manager', 'certifications', \n",
        "        'telecommute_days_per_week', 'education']\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
        "\n",
        "for i, c in enumerate(cols):\n",
        "    ax = axes.ravel()[i]\n",
        "    sns.barplot(x=c, y=\"salary\", ax=ax, data=train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqyVJ13SRu_I"
      },
      "outputs": [],
      "source": [
        "# print actual values for encoded labels of a column against which salary is highest\n",
        "print(data['employment_status'].unique().tolist()[1])\n",
        "print(data['job_title'].unique().tolist()[11])\n",
        "print(data['is_manager'].unique().tolist()[0])\n",
        "print(data['certifications'].unique().tolist()[1])\n",
        "print(data['telecommute_days_per_week'].unique().tolist()[5])\n",
        "print(data['education'].unique().tolist()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2WxcyM-Ru_L"
      },
      "source": [
        "#####  We see the following trends from above plots:\n",
        "1. People with employment_status = 1 i.e. 'Independent consultant, contractor, freelancer,  or company owner' earn more than full and half time employees. \n",
        "2. People with job_title Sr Consultant earn more than other professionals. \n",
        "3. We also see that people who hold manegrial positions earn more than those who don't.\n",
        "4. People with certifications have little difference in monthly salary than those who don't. \n",
        "5. For people having 3 or more telecommute_days_per_week, have higher salaries which might suggest that these people are actually independent contractors or freelancers. \n",
        "6. As for education, the trend shows taht people with a Bachelors degree of 4 years earn more as compared to others. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns"
      ],
      "metadata": {
        "id": "77pWJeBjefu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE5DM9CbRu_M",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "sns.heatmap(train_data.corr(), cmap=\"CMRmap\", annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg-CACeYRu_Q"
      },
      "source": [
        "##### The correlation matrix above shows that there is no correlation among the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvbUS5c5Ru_R"
      },
      "source": [
        "### Feature Encoding and Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBYOC-ybRu_S"
      },
      "source": [
        "Before training the model, we should perform one-hot encoding for all categorical/discrete variables, normalize continuous variables and then combine all data to form the training set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create another copy of dataset and append encoded features to it\n",
        "data_train = data.copy()\n",
        "\n",
        "data_train.head()"
      ],
      "metadata": {
        "id": "-4dwoGyQjuOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFmPoM11Ru_T"
      },
      "outputs": [],
      "source": [
        "# drop id, timestamp and country columns\n",
        "data_train = data_train.drop(columns=['id', 'timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg3oQCmpRu_W"
      },
      "outputs": [],
      "source": [
        "# select categorical features\n",
        "cat_cols = [c for c in data_train.columns if data_train[c].dtype == 'object' \n",
        "            and c not in ['is_manager', 'certifications']]\n",
        "cat_data = data_train[cat_cols]\n",
        "cat_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.shape"
      ],
      "metadata": {
        "id": "mSihDloIqYsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTWQSYebRu_a"
      },
      "outputs": [],
      "source": [
        "# encode binary variables\n",
        "binary_cols = ['is_manager', 'certifications']\n",
        "for c in binary_cols:\n",
        "    data_train[c] = data_train[c].replace(to_replace=['Yes'], value=1)\n",
        "    data_train[c] = data_train[c].replace(to_replace=['No'], value=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.get_dummies(data_train, columns=cat_cols, drop_first= True)\n",
        "\n",
        "final_data.shape"
      ],
      "metadata": {
        "id": "EYsSvv5JfsEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.head()"
      ],
      "metadata": {
        "id": "zbivTfzhgAnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.columns"
      ],
      "metadata": {
        "id": "7I6hzqcakErT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLH7T_t4Ru_n",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# # adding remaining cols\n",
        "# for c in data_train.columns:\n",
        "#     final_data[c] = data_train[c].values\n",
        "\n",
        "# print(final_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DaLOGRlRu_q"
      },
      "outputs": [],
      "source": [
        "# select numerical features\n",
        "num_cols = [c for c in data_train.columns if c not in cat_cols and c not in binary_cols and c != 'salary']\n",
        "num_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn_xjIt1Ru_u"
      },
      "outputs": [],
      "source": [
        "# Apply standard scaling on numeric data \n",
        "scaler = StandardScaler()\n",
        "scaler.fit(final_data[num_cols])\n",
        "final_data[num_cols] = scaler.transform(final_data[num_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yejqgyACRu_3"
      },
      "source": [
        "\n",
        "\n",
        "**The management wants to know the most important features for the model.**\n",
        "\n",
        "> #### Task:\n",
        "- **Visualize the top 20 features and their feature importance.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj8Vm6wSRu_4"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGDS_--IRu_4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y = final_data['salary']\n",
        "X = final_data.drop(columns=['salary'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(\"Training Set Dimensions:\", X_train.shape)\n",
        "print(\"Validation Set Dimensions:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "zwb5m0GJsFMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81BdZzdxRu_7"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlXExtlSRu_8"
      },
      "outputs": [],
      "source": [
        "# train random forest regression model\n",
        "randomf = RandomForestRegressor()\n",
        "\n",
        "randomf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-PKMzMtRu__"
      },
      "outputs": [],
      "source": [
        "print('MAPE for train set:', np.mean(np.abs((y_train - randomf.predict(X_train))) / y_train) * 100)\n",
        "print('MAPE for validation set:', np.mean(np.abs((y_test - randomf.predict(X_test))) / y_test) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcMzM8PXRvAF",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# compute feature importance from random forest regression model\n",
        "feature_imp=pd.DataFrame()\n",
        "for feature,imp in zip(X_train.columns,randomf.feature_importances_):\n",
        "    temp=pd.DataFrame([feature,imp]).T\n",
        "    feature_imp=feature_imp.append(temp)\n",
        "feature_imp.columns=['feature','relative_importance']\n",
        "feature_imp.sort_values(by='relative_importance',inplace=True)\n",
        "feature_imp.set_index('feature',inplace=True)\n",
        "feature_imp.iloc[-20:,:].plot(kind='barh',figsize=(10,8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU2GK5vrRvAH"
      },
      "source": [
        "> #### Task:\n",
        "- **Submit the predictions on the test dataset using the optimized model** <br/>\n",
        "    For each record in the test set (`test.csv`), predict the value of the `salary` variable. Submit a CSV file with a header row and one row per test entry. \n",
        "\n",
        "The file (`submissions.csv`) should have exactly 2 columns:\n",
        "   - **id**\n",
        "   - **salary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDtMTDxSRvAJ"
      },
      "source": [
        "### Encode and Normalize features of Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9VHPJ2oRvAK"
      },
      "outputs": [],
      "source": [
        "# store ids and drop column\n",
        "test_data = test.copy()\n",
        "ids = test_data['id']\n",
        "test_data = test_data.drop(columns=['id', 'timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwjF-xHJRvAP"
      },
      "outputs": [],
      "source": [
        "# encode binary variables\n",
        "binary_cols = ['is_manager', 'certifications']\n",
        "for c in binary_cols:\n",
        "    test_data[c] = test_data[c].replace(to_replace=['Yes'], value=1)\n",
        "    test_data[c] = test_data[c].replace(to_replace=['No'], value=0)\n",
        "\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_test_data = pd.get_dummies(test_data, columns=cat_cols, drop_first= True)\n",
        "\n",
        "encoded_test_data.shape"
      ],
      "metadata": {
        "id": "JJwWje5HktIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ez5ASc_eqJIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0bYRcjsRvAc"
      },
      "outputs": [],
      "source": [
        "# # adding remaining cols\n",
        "# for c in test_data.columns:\n",
        "#     encoded_test_data[c] = test_data[c].values\n",
        "\n",
        "# print(encoded_test_data.shape)\n",
        "# print(encoded_test_data.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwzpoOmdRvAe"
      },
      "outputs": [],
      "source": [
        "# standardize test data\n",
        "encoded_test_data[num_cols] = scaler.transform(encoded_test_data[num_cols])\n",
        "encoded_test_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yejqgyACRu_3",
        "iU2GK5vrRvAH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}